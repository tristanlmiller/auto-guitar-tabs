{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd like to try several other simple models included in sklearn.  SVM, Random Forest, Hidden Markov, Gradient Boosting (lightgbm), multiclass module of sklearn seem like good places to start.  I will make copies of `lr_train.py` for each model.  In principle I could use a different model for each of root, quality, add, and inversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T00:09:48.613503Z",
     "start_time": "2019-09-25T00:09:48.495433Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if 'chord_loader' in sys.modules:\n",
    "    del sys.modules['chord_loader']\n",
    "sys.path.append('.')\n",
    "import chord_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T22:11:40.684930Z",
     "start_time": "2019-09-24T22:11:40.380127Z"
    }
   },
   "outputs": [],
   "source": [
    "#copy code from lr_train so we can get to the point where these models can be tested. \n",
    "#Use 10% data for this purpose\n",
    "source = 'partial_lr'\n",
    "source_dir = 'Data/processed/'\n",
    "\n",
    "#get information from processed data directory\n",
    "data_info = pd.read_csv(source_dir + 'directory.csv')\n",
    "curr_data_info = data_info.loc[data_info['filepath']==source,:]\n",
    "if curr_data_info.shape[0] < 1:\n",
    "    print('Source not found in directory')\n",
    "    sys.exit(1)\n",
    "curr_data_info = curr_data_info.iloc[-1,:]\n",
    "\n",
    "#load data\n",
    "features_train = np.load(f'{source_dir}{source}_ftrain.npy')\n",
    "labels_train = np.load(f'{source_dir}{source}_ltrain.npy')\n",
    "features_valid = np.load(f'{source_dir}{source}_fvalid.npy')\n",
    "labels_valid = np.load(f'{source_dir}{source}_lvalid.npy')\n",
    "features_test = np.load(f'{source_dir}{source}_ftest.npy')\n",
    "labels_test = np.load(f'{source_dir}{source}_ltest.npy')\n",
    "if curr_data_info['standard']:\n",
    "    standard_features_train = np.load(f'{source_dir}{source}_fstrain.npy')\n",
    "    standard_labels_train = np.load(f'{source_dir}{source}_lstrain.npy')\n",
    "    standard_features_valid = np.load(f'{source_dir}{source}_fsvalid.npy')\n",
    "    standard_labels_valid = np.load(f'{source_dir}{source}_lsvalid.npy')\n",
    "    standard_features_test = np.load(f'{source_dir}{source}_fstest.npy')\n",
    "    standard_labels_test = np.load(f'{source_dir}{source}_lstest.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've trained a logistic regression model already, but I'll train it in this specific setting just to get a baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T23:48:02.572826Z",
     "start_time": "2019-09-24T23:46:57.743228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=1000, multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_model = LogisticRegression(class_weight='balanced',multi_class='ovr',C=1.0,\n",
    "                                                    solver='lbfgs', max_iter=1000)\n",
    "root_model.fit(features_train, labels_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T23:51:41.771109Z",
     "start_time": "2019-09-24T23:51:41.517838Z"
    }
   },
   "outputs": [],
   "source": [
    "root_predict_train = root_model.predict(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T23:51:42.475811Z",
     "start_time": "2019-09-24T23:51:42.413788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3485297784426872"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(labels_train[:,0],root_predict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 minute to train, 35% accuracy.  Adequate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T22:31:36.074349Z",
     "start_time": "2019-09-24T22:20:04.940570Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=1000, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure function behaves like I expect\n",
    "root_model = SVC(class_weight='balanced',decision_function_shape='ovr',C=1.0, max_iter=1000)\n",
    "root_model.fit(features_train, labels_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T23:33:02.984250Z",
     "start_time": "2019-09-24T22:51:43.737275Z"
    }
   },
   "outputs": [],
   "source": [
    "root_predict_train = root_model.predict(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T23:41:55.999562Z",
     "start_time": "2019-09-24T23:41:55.970225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0361722590297072"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(labels_train[:,0],root_predict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 minutes to train, 40 minutes to just make a prediction, and 4% accuracy!  Maybe SVM is bad for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T00:14:44.845569Z",
     "start_time": "2019-09-25T00:09:50.687101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_model = RandomForestClassifier(n_estimators=100,max_features='sqrt',class_weight=None)\n",
    "root_model.fit(features_train, labels_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T00:18:55.022124Z",
     "start_time": "2019-09-25T00:18:43.082439Z"
    }
   },
   "outputs": [],
   "source": [
    "root_predict_train = root_model.predict(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T00:18:58.363381Z",
     "start_time": "2019-09-25T00:18:58.325088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995672152169267"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(labels_train[:,0],root_predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T00:33:32.523349Z",
     "start_time": "2019-09-25T00:33:31.798185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3724286152901443"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try that again on the validation set\n",
    "root_predict_valid = root_model.predict(features_valid)\n",
    "sklearn.metrics.accuracy_score(labels_valid[:,0],root_predict_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's obviously in the high variance regime, but that might improve as I add more data.  This one is worth trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`source destination [--weighted --num num_estimators --frac fraction --metrics]`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
